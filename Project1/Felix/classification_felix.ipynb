{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0551027d1b939ec0016f2e01e6bd6ac0e4699d2ec5e4974e783e9fca478101a51",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project 1 - Classification, weight sharing, auxiliary losses\n",
    "\n",
    "This notebook contains my ideas concerning the first question of the project. \n",
    "\n",
    ">The goal of the project is to compare different architectures, and assess the performance improvement\n",
    "that can be achieved through weight sharing, or using auxiliary losses. For the latter, the training can\n",
    "in particular take advantage of the availability of the classes of the two digits in each pair, beside the\n",
    "Boolean value truly of interest. \n",
    "\n",
    ">All the experiments should be done with 1000 pairs for training and test. A convnet with around 70000\n",
    "parameters can be trained with 25 epochs in the VM in less than 2s and should achieve around 15% error\n",
    "rate. \n",
    "\n",
    ">Performance estimates provided in your report should be estimated through 10+ rounds for each\n",
    "architecture, where both data and weight initialization are randomized, and you should provide estimates\n",
    "of standard deviations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## TODO:\n",
    "- get rid of aux network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Models\n",
    "from models_felix import *\n",
    "\n",
    "# Import data generating function\n",
    "from dlc_practical_prologue import generate_pair_sets\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## Import data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1000, 2, 14, 14])\ntorch.Size([1000])\ntorch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(nb=1000)\n",
    "\n",
    "# Print dimensions\n",
    "print(train_input.size())\n",
    "print(train_target.size())\n",
    "print(train_classes.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "train_mean = train_input.mean()\n",
    "train_std = train_input.std()\n",
    "\n",
    "train_input -= train_mean\n",
    "test_input -= train_mean\n",
    "\n",
    "train_input /= train_std\n",
    "test_input /= train_std"
   ]
  },
  {
   "source": [
    "## Training and testing function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(X_test, y_test, model, y_aux = None):\n",
    "    # Put model in test model\n",
    "    model.eval()\n",
    "\n",
    "    if y_aux == None:\n",
    "        out = model(X_test).argmax(dim=1)\n",
    "        err = (out != y_test).sum()\n",
    "        return err/y_test.size(0)\n",
    "    else:\n",
    "        out, out_aux = model(X_test)\n",
    "        out, out_aux = out.argmax(dim=1), out_aux.argmax(dim=1)\n",
    "        err = (out != y_test).sum()\n",
    "        err_aux = (out_aux != y_aux).sum()\n",
    "        return err/y_test.size(0), err_aux/y_aux.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, \n",
    "            train_input, train_target, train_classes,\n",
    "            test_input, test_target, test_classes,\n",
    "            lr = 0.1,\n",
    "            schedule_lr = True, # Learning rate sheduling\n",
    "            tb_logging = True, # Tensorboard logging\n",
    "            mini_batch_size = 100,\n",
    "            nb_epochs = 1,\n",
    "            verbose = True):\n",
    "\n",
    "    # Parmas\n",
    "    print_every = int(0.1 * nb_epochs)\n",
    "    if print_every == 0: print_every = 1\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Loss criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Logging\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # Lerning rate sheduler\n",
    "    if schedule_lr:\n",
    "        nb_steps = 10\n",
    "        step_size = 1 if nb_epochs <= nb_steps else int(nb_epochs/nb_steps)\n",
    "        gamma = 0.65\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    # Iterate over epochs\n",
    "    for e in range(nb_epochs):\n",
    "        # Learning rate sheduler step\n",
    "        if e != 0 and schedule_lr: lr_scheduler.step()\n",
    "\n",
    "        # Set model in training mode\n",
    "        model.train()\n",
    "\n",
    "        # Iterate over minibatches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if model.loss_mode == 'train_with_aux':\n",
    "                out, out_aux = model(train_input.narrow(0, b, mini_batch_size))\n",
    "\n",
    "                loss_target = criterion(out, train_target.narrow(0, b, mini_batch_size))\n",
    "                loss_aux = criterion(out_aux, train_classes.narrow(0, b, mini_batch_size).T.reshape(-1))\n",
    "                loss = loss_target + loss_aux\n",
    "            elif model.loss_mode == 'train_aux_only':\n",
    "                out_aux = model(train_input.narrow(0, b, mini_batch_size))\n",
    "\n",
    "                loss = criterion(out_aux, train_classes.narrow(0, b, mini_batch_size).T.reshape(-1))\n",
    "            elif model.loss_mode == 'train_without_aux':\n",
    "                out = model(train_input.narrow(0, b, mini_batch_size))\n",
    "\n",
    "                loss = criterion(out, train_target.narrow(0, b, mini_batch_size))\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        if tb_logging:\n",
    "            # Get error rates\n",
    "            error_rate_test = testing(test_input, test_target, model)\n",
    "            error_rate_training = testing(train_input, train_target, model)\n",
    "\n",
    "            # Write\n",
    "            writer.add_scalar('Accuracy/testing', 1-error_rate_test, e)\n",
    "            writer.add_scalar('Accuracy/training', 1-error_rate_training, e)\n",
    "            writer.add_scalar('Loss/training', loss)\n",
    "\n",
    "        # Printing\n",
    "        if verbose and ((e+1) % print_every == 0 or e+1==nb_epochs):\n",
    "            # Get error rate\n",
    "            if model.loss_mode == 'train_aux_only':\n",
    "                test_classes = test_classes.T.reshape(-1)\n",
    "                error_rate_test = testing(test_input, test_classes, model)\n",
    "                print(\"### Epoch {:3d}: Auxillary error ={:.2f}% ###\".format(e+1, error_rate_test*100))\n",
    "            elif model.loss_mode == 'train_without_aux':\n",
    "                error_rate_test = testing(test_input, test_target, model)\n",
    "                print(\"### Epoch {:3d}: Target error ={:.2f}% ###\".format(e+1, error_rate_test*100))\n",
    "            elif model.loss_mode == 'train_with_aux':\n",
    "                test_classes = test_classes.T.reshape(-1)\n",
    "                error_rate_target_test, error_rate_aux_test = testing(test_input, test_target, model, test_classes)\n",
    "                print(\"### Epoch {:3d}: Auxillary error ={:.2f}%, Target error ={:.2f}% ###\".format(e+1, error_rate_aux_test*100, error_rate_target_test*100))\n",
    "        \n",
    "    # Loggging\n",
    "    if tb_logging:\n",
    "        writer.close()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "source": [
    "## Let's do it!\n",
    "### Auxillary loss only (MNIST classification)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "convNet = SimpleConvNet()\n",
    "auxNet = AuxNet(in_features=576)\n",
    "classNet = None\n",
    "mode = 'train_aux_only'\n",
    "\n",
    "model1 = CombinedBaseModel(ConvNet=convNet, AuxNet=auxNet, ClassNet=classNet, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Epoch   2: Auxillary error =78.10% ###\n",
      "### Epoch   4: Auxillary error =57.00% ###\n",
      "### Epoch   6: Auxillary error =14.30% ###\n",
      "### Epoch   8: Auxillary error =43.60% ###\n",
      "### Epoch  10: Auxillary error =6.35% ###\n",
      "### Epoch  12: Auxillary error =6.35% ###\n",
      "### Epoch  14: Auxillary error =6.15% ###\n",
      "### Epoch  16: Auxillary error =5.85% ###\n",
      "### Epoch  18: Auxillary error =5.45% ###\n",
      "### Epoch  20: Auxillary error =5.30% ###\n",
      "### Epoch  22: Auxillary error =5.50% ###\n",
      "### Epoch  24: Auxillary error =5.45% ###\n",
      "### Epoch  25: Auxillary error =5.35% ###\n"
     ]
    }
   ],
   "source": [
    "# Train it\n",
    "model1 = training(model1,\n",
    "                train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                lr = 0.1,\n",
    "                nb_epochs=25, tb_logging=False, schedule_lr=False)"
   ]
  },
  {
   "source": [
    "### Target loss only"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "convNet = SimpleConvNet()\n",
    "auxNet = None\n",
    "classNet = ClassNet(in_features=1152)\n",
    "mode = 'train_without_aux'\n",
    "\n",
    "model2 = CombinedBaseModel(ConvNet=convNet, AuxNet=auxNet, ClassNet=classNet, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Epoch   2: Target error =32.00% ###\n",
      "### Epoch   4: Target error =54.00% ###\n",
      "### Epoch   6: Target error =25.20% ###\n",
      "### Epoch   8: Target error =25.00% ###\n",
      "### Epoch  10: Target error =17.90% ###\n",
      "### Epoch  12: Target error =30.50% ###\n",
      "### Epoch  14: Target error =19.50% ###\n",
      "### Epoch  16: Target error =18.70% ###\n",
      "### Epoch  18: Target error =18.40% ###\n",
      "### Epoch  20: Target error =18.40% ###\n",
      "### Epoch  22: Target error =18.90% ###\n",
      "### Epoch  24: Target error =15.40% ###\n",
      "### Epoch  25: Target error =16.90% ###\n"
     ]
    }
   ],
   "source": [
    "# Train it\n",
    "model2 = training(model2,\n",
    "                train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                lr = 0.1,\n",
    "                nb_epochs=25, tb_logging=False, schedule_lr=False)"
   ]
  },
  {
   "source": [
    "### Using auxillary and target loss"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "convNet = SimpleConvNet()\n",
    "auxNet = AuxNet(in_features=576)\n",
    "classNet = ClassNet(in_features=1152)\n",
    "mode = 'train_with_aux'\n",
    "\n",
    "model3 = CombinedBaseModel(ConvNet=convNet, AuxNet=auxNet, ClassNet=classNet, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### Epoch   2: Auxillary error =75.25%, Target error =37.50% ###\n",
      "### Epoch   4: Auxillary error =30.00%, Target error =27.30% ###\n",
      "### Epoch   6: Auxillary error =39.25%, Target error =26.70% ###\n",
      "### Epoch   8: Auxillary error =29.65%, Target error =18.40% ###\n",
      "### Epoch  10: Auxillary error =9.25%, Target error =17.40% ###\n",
      "### Epoch  12: Auxillary error =9.35%, Target error =15.30% ###\n",
      "### Epoch  14: Auxillary error =9.65%, Target error =16.00% ###\n",
      "### Epoch  16: Auxillary error =7.15%, Target error =13.80% ###\n",
      "### Epoch  18: Auxillary error =8.80%, Target error =13.20% ###\n",
      "### Epoch  20: Auxillary error =10.60%, Target error =18.90% ###\n",
      "### Epoch  22: Auxillary error =6.25%, Target error =13.20% ###\n",
      "### Epoch  24: Auxillary error =6.90%, Target error =13.70% ###\n",
      "### Epoch  25: Auxillary error =6.30%, Target error =13.00% ###\n"
     ]
    }
   ],
   "source": [
    "# Train it\n",
    "model3 = training(model3,\n",
    "                train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                lr = 0.1,\n",
    "                nb_epochs=25, tb_logging=False, schedule_lr=False)"
   ]
  },
  {
   "source": [
    "### First training auxillary network, than target network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training auxillary network:\n",
      "### Epoch   1: Auxillary error =50.40% ###\n",
      "### Epoch   2: Auxillary error =87.95% ###\n",
      "### Epoch   3: Auxillary error =51.75% ###\n",
      "### Epoch   4: Auxillary error =44.70% ###\n",
      "### Epoch   5: Auxillary error =53.50% ###\n",
      "### Epoch   6: Auxillary error =23.05% ###\n",
      "### Epoch   7: Auxillary error =15.95% ###\n",
      "### Epoch   8: Auxillary error =14.65% ###\n",
      "### Epoch   9: Auxillary error =9.50% ###\n",
      "### Epoch  10: Auxillary error =9.75% ###\n",
      "Training without auxillary network:\n",
      "### Epoch   1: Target error =27.40% ###\n",
      "### Epoch   2: Target error =22.40% ###\n",
      "### Epoch   3: Target error =21.40% ###\n",
      "### Epoch   4: Target error =19.00% ###\n",
      "### Epoch   5: Target error =19.40% ###\n",
      "### Epoch   6: Target error =17.80% ###\n",
      "### Epoch   7: Target error =16.20% ###\n",
      "### Epoch   8: Target error =21.10% ###\n",
      "### Epoch   9: Target error =15.90% ###\n",
      "### Epoch  10: Target error =15.60% ###\n",
      "### Epoch  11: Target error =15.90% ###\n",
      "### Epoch  12: Target error =15.40% ###\n",
      "### Epoch  13: Target error =14.90% ###\n",
      "### Epoch  14: Target error =14.90% ###\n",
      "### Epoch  15: Target error =15.30% ###\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "convNet = SimpleConvNet()\n",
    "auxNet = AuxNet(in_features=576)\n",
    "classNet = ClassNet(in_features=1152)\n",
    "mode = 'train_aux_only'\n",
    "\n",
    "model3 = CombinedBaseModel(ConvNet=convNet, AuxNet=auxNet, ClassNet=classNet, mode=mode)\n",
    "\n",
    "print(\"Training auxillary network:\")\n",
    "model3 = training(model3,\n",
    "                train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                lr = 0.1,\n",
    "                nb_epochs=10, tb_logging=False, schedule_lr=False)\n",
    "\n",
    "# Changing loss mode\n",
    "mode = 'train_without_aux'\n",
    "model3.loss_mode = mode\n",
    "\n",
    "print(\"Training without auxillary network:\")\n",
    "model3 = training(model3,\n",
    "                train_input, train_target, train_classes,\n",
    "                test_input, test_target, test_classes,\n",
    "                lr = 0.1,\n",
    "                nb_epochs=15, tb_logging=False, schedule_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}