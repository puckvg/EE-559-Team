{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "551027d1b939ec0016f2e01e6bd6ac0e4699d2ec5e4974e783e9fca478101a51"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project 1 - Classification, weight sharing, auxiliary losses\n",
    "\n",
    "This notebook contains my ideas concerning the first question of the project. \n",
    "\n",
    ">The goal of the project is to compare different architectures, and assess the performance improvement\n",
    "that can be achieved through weight sharing, or using auxiliary losses. For the latter, the training can\n",
    "in particular take advantage of the availability of the classes of the two digits in each pair, beside the\n",
    "Boolean value truly of interest. \n",
    "\n",
    ">All the experiments should be done with 1000 pairs for training and test. A convnet with around 70000\n",
    "parameters can be trained with 25 epochs in the VM in less than 2s and should achieve around 15% error\n",
    "rate. \n",
    "\n",
    ">Performance estimates provided in your report should be estimated through 10+ rounds for each\n",
    "architecture, where both data and weight initialization are randomized, and you should provide estimates\n",
    "of standard deviations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "\n",
    "# Import function\n",
    "from dlc_practical_prologue import generate_pair_sets\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## Import data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1000, 2, 14, 14])\ntorch.Size([1000])\ntorch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(nb=1000)\n",
    "\n",
    "# Print dimensions\n",
    "print(train_input.size())\n",
    "print(train_target.size())\n",
    "print(train_classes.size())"
   ]
  },
  {
   "source": [
    "## Defining the network\n",
    "\n",
    "- How to use multiple losses in PyTorch: https://stackoverflow.com/questions/53994625/how-can-i-process-multi-loss-in-pytorch/53995165"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FelixNet(nn.Module):\n",
    "    def __init__():\n",
    "        super().__init__(self)\n",
    "\n",
    "        # Define layers\n",
    "        self.conv = None\n",
    "        self.bn = None\n",
    "        self.fc = None\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(nb_epochs=1, batch_size=64, verbose=False):\n",
    "\n",
    "        # Iterate over epochs and batches\n",
    "        for e in nb_epochs:\n",
    "\n",
    "\n"
   ]
  }
 ]
}