{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "551027d1b939ec0016f2e01e6bd6ac0e4699d2ec5e4974e783e9fca478101a51"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Practical Session 6"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Import data\n",
    "cifar_train_set = datasets.CIFAR10('./data/cifar10/', train = True, download = True)\n",
    "train_input = torch.from_numpy(cifar_train_set.data).permute(0, 3, 1, 2).float()\n",
    "train_targets = torch.tensor(cifar_train_set.targets, dtype = torch.int64)\n",
    "\n",
    "mu, std = train_input.mean(), train_input.std()\n",
    "train_input = train_input.sub_(mu).div_(std)\n",
    "\n",
    "train_input.size()"
   ]
  },
  {
   "source": [
    "## Modification of the ResNet implementation\n",
    "\n",
    "Edit the implementation of the ResNet and ResNetBlock so that you can pass two Boolean flags\n",
    "`skip_connections` and `batch_normalization` to specify if these features are activated or not."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, nb_channels, kernel_size, skip_connections=True, batch_normalization=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.skip_connections = skip_connections\n",
    "        self.batch_normalization = batch_normalization\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nb_channels, nb_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               padding = (kernel_size - 1) // 2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(nb_channels, nb_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               padding = (kernel_size - 1) // 2)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        if self.batch_normalization: y = self.bn1(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        if self.batch_normalization: y = self.bn2(y)\n",
    "        if self.skip_connections: y = y + x\n",
    "        y = F.relu(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_residual_blocks, nb_channels,\n",
    "                 kernel_size = 3, nb_classes = 10,\n",
    "                 batch_normalization=True,\n",
    "                 skip_connections=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.skip_connections = skip_connections\n",
    "\n",
    "        # Layer definition\n",
    "        self.conv = nn.Conv2d(3, nb_channels,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = (kernel_size - 1) // 2)\n",
    "        self.bn = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "        self.resnet_blocks = nn.Sequential(\n",
    "            *(ResNetBlock(nb_channels, kernel_size, skip_connections, batch_normalization)\n",
    "              for _ in range(nb_residual_blocks))\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(nb_channels, nb_classes)\n",
    "\n",
    "    def forward(self, x, minibatch_size=32):\n",
    "        x = self.conv(x)\n",
    "        if self.batch_normalization: x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.resnet_blocks(x)\n",
    "        x = F.avg_pool2d(x, 32).view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "## Monitoring the gradient norm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(skip_connections, batch_normalization):\n",
    "    # Create model\n",
    "    model = ResNet(nb_residual_blocks=30, nb_channels=10, kernel_size=3, \n",
    "        skip_connections=skip_connections, batch_normalization=batch_normalization)\n",
    "\n",
    "    # Loss criteria\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Initialize\n",
    "    grad_norm = torch.zeros(30, 100)\n",
    "\n",
    "    # Loop over 100 samples\n",
    "    for i in range(100):\n",
    "        # Reset gradient\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Get sample\n",
    "        image = train_input[i:i+1]\n",
    "        target = train_targets[i:i+1]\n",
    "\n",
    "        # Calculate gradient\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        # Get model params\n",
    "        grad_norm[:,i] = torch.Tensor([ b.conv1.weight.grad.norm() for b in model.resnet_blocks ])\n",
    "\n",
    "    return grad_norm"
   ]
  },
  {
   "source": [
    "## Graph"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-2.4543,  2.2286,  0.4680,  1.6983, -2.7910, -1.2428,  3.5782, -0.6584,\n",
      "          2.3081,  0.2355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5272,  2.4931,  0.5515,  1.9310, -2.9782, -1.2644,  3.7377, -0.5942,\n",
      "          2.4302,  0.3174]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.4883,  2.6449,  0.5420,  1.8979, -2.9956, -1.2168,  3.6885, -0.6082,\n",
      "          2.4468,  0.3590]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.3910,  2.2913,  0.4873,  1.7617, -2.7692, -1.0447,  3.4525, -0.5127,\n",
      "          2.1491,  0.3367]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5028,  2.5021,  0.4732,  1.8700, -2.9078, -1.2410,  3.6518, -0.6218,\n",
      "          2.3220,  0.3117]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5928,  2.3989,  0.5092,  1.9539, -2.9474, -1.2832,  3.7891, -0.6107,\n",
      "          2.3410,  0.2483]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5856,  2.5118,  0.4913,  1.9759, -2.9961, -1.3487,  3.8890, -0.6264,\n",
      "          2.5003,  0.3243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6781,  2.5175,  0.4721,  1.9460, -2.9984, -1.3140,  3.8445, -0.6844,\n",
      "          2.4754,  0.2635]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5573,  2.4178,  0.3775,  1.8367, -2.7940, -1.1754,  3.6779, -0.6506,\n",
      "          2.3540,  0.2626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5436,  2.4380,  0.5078,  1.8133, -2.8879, -1.1696,  3.6891, -0.6257,\n",
      "          2.4302,  0.2889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6396,  2.4928,  0.5119,  1.9394, -2.9978, -1.3276,  3.8438, -0.6867,\n",
      "          2.4841,  0.2591]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6240,  2.4868,  0.4920,  1.9692, -2.9566, -1.2770,  3.8328, -0.6515,\n",
      "          2.3500,  0.2695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6897,  2.5099,  0.4550,  1.9628, -2.9552, -1.2837,  3.9446, -0.6565,\n",
      "          2.5336,  0.2640]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6099,  2.5541,  0.4841,  1.9106, -2.9382, -1.2261,  3.7851, -0.6958,\n",
      "          2.4641,  0.2926]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6375,  2.5725,  0.5092,  1.9021, -3.0001, -1.2101,  3.8543, -0.5632,\n",
      "          2.4537,  0.3320]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.4435,  2.4514,  0.4626,  1.8248, -2.9037, -1.3124,  3.6059, -0.6449,\n",
      "          2.3887,  0.2808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5773,  2.4831,  0.4825,  1.8487, -2.9601, -1.2646,  3.7726, -0.6057,\n",
      "          2.3873,  0.3000]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5269,  2.4901,  0.5072,  1.9326, -2.9119, -1.1796,  3.7465, -0.5728,\n",
      "          2.3997,  0.3297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6624,  2.6446,  0.4884,  2.0437, -3.0322, -1.2188,  3.8849, -0.6288,\n",
      "          2.4284,  0.3647]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5733,  2.4532,  0.4413,  1.8919, -2.9059, -1.2645,  3.7995, -0.5783,\n",
      "          2.3881,  0.2800]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.4603,  2.3960,  0.5135,  1.8116, -2.8857, -1.1964,  3.6394, -0.5653,\n",
      "          2.2695,  0.2861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6881,  2.5475,  0.5586,  1.9108, -3.0916, -1.1856,  3.8872, -0.4473,\n",
      "          2.4437,  0.3267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5434,  2.4777,  0.4575,  1.9315, -2.8684, -1.1972,  3.7512, -0.6424,\n",
      "          2.4162,  0.3317]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5893,  2.4978,  0.5168,  1.9592, -2.9760, -1.2489,  3.7789, -0.5963,\n",
      "          2.3763,  0.3075]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5582,  2.4297,  0.4250,  1.8694, -2.8207, -1.2729,  3.7284, -0.7429,\n",
      "          2.4159,  0.2594]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6517,  2.5205,  0.4762,  1.9799, -2.9747, -1.1923,  3.8444, -0.5891,\n",
      "          2.3891,  0.3246]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5771,  2.5008,  0.5118,  1.9359, -2.9385, -1.3258,  3.8075, -0.6701,\n",
      "          2.4350,  0.2503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5433,  2.3484,  0.4072,  1.8684, -2.8262, -1.2667,  3.7154, -0.6981,\n",
      "          2.3773,  0.2684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5882,  2.4950,  0.5119,  1.8685, -2.9872, -1.3289,  3.7747, -0.6693,\n",
      "          2.3877,  0.2684]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6512,  2.6001,  0.4306,  1.9776, -2.9247, -1.2346,  3.8424, -0.7089,\n",
      "          2.4070,  0.3027]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.2708,  2.2067,  0.3862,  1.7061, -2.5986, -0.9702,  3.2818, -0.5168,\n",
      "          2.0572,  0.3310]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5364,  2.4247,  0.4674,  1.8331, -2.8941, -1.2283,  3.6979, -0.6330,\n",
      "          2.3382,  0.2818]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6236,  2.6420,  0.5261,  2.0236, -3.0551, -1.3083,  3.9147, -0.6326,\n",
      "          2.4720,  0.3425]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6335,  2.4920,  0.4987,  1.9145, -2.9940, -1.3562,  3.8518, -0.7118,\n",
      "          2.4578,  0.2719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6307,  2.5556,  0.4487,  2.0299, -2.9602, -1.2655,  3.8364, -0.6569,\n",
      "          2.4672,  0.3235]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6453,  2.5429,  0.5343,  2.0132, -3.0629, -1.2302,  3.8724, -0.4952,\n",
      "          2.4612,  0.3377]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5156,  2.3584,  0.5022,  1.7720, -2.8416, -1.2179,  3.6983, -0.6086,\n",
      "          2.3083,  0.2396]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6183,  2.5094,  0.4718,  2.0213, -2.9729, -1.2962,  3.9112, -0.6099,\n",
      "          2.4745,  0.3261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5152,  2.5679,  0.5415,  1.9014, -3.0000, -1.3345,  3.7908, -0.6077,\n",
      "          2.4732,  0.3195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5360,  2.4033,  0.4348,  1.8743, -2.8474, -1.1769,  3.7015, -0.6256,\n",
      "          2.3492,  0.3305]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5776,  2.3199,  0.4110,  1.8486, -2.8177, -1.2963,  3.7296, -0.7054,\n",
      "          2.3350,  0.2118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.4194,  2.1206,  0.3736,  1.7741, -2.6951, -1.1686,  3.5779, -0.5248,\n",
      "          2.1652,  0.2444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5792,  2.5764,  0.5231,  1.9611, -3.0229, -1.2627,  3.8442, -0.5473,\n",
      "          2.4494,  0.3201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6287,  2.7127,  0.5235,  2.0434, -3.0669, -1.3480,  3.8619, -0.6766,\n",
      "          2.4734,  0.3190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5614,  2.4184,  0.5054,  1.8756, -2.9252, -1.2576,  3.7708, -0.5982,\n",
      "          2.3407,  0.2809]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.6119,  2.6473,  0.5753,  2.0008, -3.0551, -1.2842,  3.8418, -0.6633,\n",
      "          2.4836,  0.3247]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a46499bb9f93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_normalization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# Get gradient norms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mgrad_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Calcualte average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-e78ed9c4355f>\u001b[0m in \u001b[0;36mget_stats\u001b[1;34m(skip_connections, batch_normalization)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# Calculate gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ce9502a18571>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 420\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "skip_connections = [True, False]\n",
    "batch_normalization = [True, False]\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.yscale('log')\n",
    "\n",
    "for sc in skip_connections:\n",
    "    for bn in batch_normalization:\n",
    "        # Get gradient norms\n",
    "        grad_norm = get_stats(sc, bn)\n",
    "\n",
    "        # Calcualte average\n",
    "        grad_mean = grad_norm.mean(dim=1)\n",
    "\n",
    "        # Plot  \n",
    "        plt.plot([i+1 for i in range(30)], grad_mean.numpy(), label = \"skip={}, norm={}\".format(sc, bn))\n",
    "\n",
    "# Styling\n",
    "plt.xlabel(\"depth\")\n",
    "plt.ylabel(\"average grad norm\")\n",
    "plt.xlim(1,30)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}