{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "551027d1b939ec0016f2e01e6bd6ac0e4699d2ec5e4974e783e9fca478101a51"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Practical Session 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "* Using MNIST\n** Reduce the data-set (use --full for the full thing)\n** Use 1000 train and 1000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False, full=False)\n",
    "\n",
    "# Move to GPU\n",
    "if torch.cuda.is_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "    train_input = train_input.to(device) \n",
    "    train_target = train_target.to(device)\n",
    "    test_input = test_input.to(device)\n",
    "    test_target = test_target.to(device)"
   ]
  },
  {
   "source": [
    "## Training function\n",
    "\n",
    "Re-organize the code to define and use a function\n",
    "\n",
    "`train_model(model, train_input, train_target, mini_batch_size)`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_units=200):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, 10)\n",
    "        # Hyperparameters\n",
    "        self.eta = 1e-1\n",
    "        self.nb_epochs = 25\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def train_model(self, train_input, train_target, mini_batch_size, verbose=False):\n",
    "        # Iterate over epochs\n",
    "        for e in range(self.nb_epochs):\n",
    "            acc_loss = 0\n",
    "            # Iterate over mini-batches\n",
    "            for b in range(0, train_input.size(0), mini_batch_size):\n",
    "                print(b)\n",
    "                print(train_input.narrow(0, b, mini_batch_size))\n",
    "                output = self(train_input.narrow(0, b, mini_batch_size))\n",
    "                loss = self.criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "                acc_loss = acc_loss + loss.item()\n",
    "\n",
    "                model.zero_grad()\n",
    "                loss.backward()\n",
    "                with torch.no_grad():\n",
    "                    for p in model.parameters():\n",
    "                        p -= self.eta * p.grad\n",
    "            if verbose:\n",
    "                print(e, acc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "model.train_model(train_input, train_target, 100)"
   ]
  },
  {
   "source": [
    "## Test error\n",
    "\n",
    "Write and test a function  \n",
    "`compute_nb_errors(model, input, target, mini_batch_size)`  \n",
    "To compute the number of prediction mistakes using a \"winner-take-all\" rule, that is the class with\n",
    "the largest output is the predicted one.  \n",
    "\n",
    "Run the training and test ten times, record the test error rates.  \n",
    "With 25 epochs for training, the test error should be around 10% with the small sets, and around\n",
    "0.7% with the full ones."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test error: 11.60%\n"
     ]
    }
   ],
   "source": [
    "def compute_nb_errors(self, input, target, mini_batch_size):\n",
    "    y_predicted = torch.argmax(model.forward(test_input), dim=1)\n",
    "    y = torch.argmax(target, dim=1)\n",
    "\n",
    "    # Compare predicted labels with true targets\n",
    "    e = (y_predicted != y).sum() / target.size(0)\n",
    "    return e\n",
    "\n",
    "# Add method to class\n",
    "model.compute_nb_errors = compute_nb_errors.__get__(model)\n",
    "\n",
    "# Test trained model\n",
    "error = model.compute_nb_errors(test_input, test_target, 100)\n",
    "print(\"Test error: {:.2f}%\".format(error*100))"
   ]
  },
  {
   "source": [
    "## Influence of the number of hidden units\n",
    "\n",
    "In the default network, the number of hidden units is 200.  \n",
    "Modify the class constructor to take a parameter for that value, and run the training and compute the\n",
    "test error for 10, 50, 200, 500, and 1,000 hidden units."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test error using 10 hidden units: 12.40%\n",
      "Test error using 50 hidden units: 6.50%\n",
      "Test error using 200 hidden units: 7.40%\n",
      "Test error using 500 hidden units: 5.20%\n",
      "Test error using 1000 hidden units: 5.30%\n",
      "Test error using 10000 hidden units: 39.50%\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [10, 50, 200, 500, 1000, 10000]\n",
    "for hu in hidden_units:\n",
    "    # Definition and training\n",
    "    model = Net(hidden_units = hu).to(device)\n",
    "    model.nb_epochs = 100\n",
    "    model.train_model(train_input, train_target, 100)\n",
    "\n",
    "    # Testing\n",
    "    model.compute_nb_errors = compute_nb_errors.__get__(model)\n",
    "    error = model.compute_nb_errors(test_input, test_target, 100)\n",
    "    print(\"Test error using {:d} hidden units: {:.2f}%\".format(hu, error*100))"
   ]
  },
  {
   "source": [
    "## Three convolutional layers\n",
    "\n",
    "Write a new class Net2 with three convolutional layers. Pick the structure you want."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(Net):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.conv3 = nn.Conv2d(64, 256, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def compute_nb_errors(self, input, target, mini_batch_size):\n",
    "        return compute_nb_errors(self, input, target, mini_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test error: 11.50%\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = Net2().to(device)\n",
    "model.nb_epochs = 100\n",
    "\n",
    "# Train model\n",
    "model.train_model(train_input, train_target, 100)\n",
    "\n",
    "# Evaluate model\n",
    "error = model.compute_nb_errors(test_input, test_target, 100)\n",
    "print(\"Test error: {:.2f}%\".format(error*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}